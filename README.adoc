= Spring Integration - Apache Kafka - MongoDB sample application

La aplicación contiene dos módulos que se comunican a través de una cola de Kafka. El primer módulo
será un gateway que expondrá una API REST a través de la cual recibirá las peticiones. El segundo
módulo contendrá la lógica de negocio escuchando los mensajes de una cola de Kafka utilizando para
ello Spring Integration DSL.

[source]
----
[http]       [app-gateway]    [kafka]    [app-core]      [mongo]
  |-------------->|              |           |              |
  |               |------------->| [1]       |              |
  |               |              |           |              |
  |               |              |---------->|              |
  |               |              |           |<------------>|
  |               |              |<----------|              |
  |               |<-------------| [2]       |              |
  |<--------------|              |           |              |          
----

[1]: _tf-calculator-in_
[2]: _tf-calculator-out_

La información sobre cada cálculo se persistirá en mongodb, que también será utilizado para
recuperar aquella información de negocio necesaria para realizar los cálculos.

*¿Por qué utilizar Spring Integration?*

La principal ventaja es que abstrae a nuestra aplicación de la infraestructura que vamos a tener. Por ejemplo la
aplicación se podría cambiar de forma muy sencilla reemplazando Kafka por AMQP (RabbitMQ por ejemplo). De este
modo simplemente tendríamos que tocar la configuración de integración cambiando por ejemplo:

[source,java]
----
IntegrationFlows
  .from(
    Kafka
      .messageDrivenChannelAdapter(consumerFactory, Topics.CalculationIn))
----

por:

[source,java]
----
IntegrationFlows
  .from(
    Amqp
	  .inboundGateway(connectionFactory, amqpTemplate, contractCreateQueue())
		.errorChannel(contractCreationErrorChannel())
----

Manteniendo el resto de la aplicación funcionando del mismo modo.

== Gateway app

Este proyecto está construído con _maven_. Básicamente consta de un `@MessagingGateway` a partir del cual realizaremos
las llamadas a partir del controlador `CalculatorController`:

[source,java]
----
@RestController
@Slf4j
public class CalculatorController {

    @Autowired
    private CalculatorGateway gateway;

    @PostMapping(Constants.Rest.CalculationRequestPath)
    public CalculationResponse calculate(@RequestBody CalculationRequest request) { ... }
}
----

Nuestro gateway se integra con los dos canales de entrada y salida que hemos definido en la clase `IntegrationConfiguration`.

En primer lugar nuestro canal de entrada enviará los mensajes que recibe a Kafka:

[source,java]
----
@Bean
IntegrationFlow inputChannelToKafkaFlow(
    KafkaTemplate<String, String> kafkaTemplate,
    JsonObjectMapper<?, ?> mapper) {

  return IntegrationFlows
    .from(MessageChannels.publishSubscribe(Channels.CalculationIn))
    .transform(Transformers.toJson(mapper))
    .log(Level.INFO, "channel -> kafka")
    .handle(Kafka
      .outboundChannelAdapter(kafkaTemplate)
      .messageKey(MessageKeys.CalculationMessageKey)
      .topic(Topics.CalculationIn))
    .get();
}
----

Y para recibir las respuestas escucha de Kafka enviando los mensajes al canal que escucha nuestro Gateway:

[source,java]
----
@Bean
IntegrationFlow kafkaToOutputChannelFlow(
    ConsumerFactory<String, String> consumerFactory,
    JsonObjectMapper<?, ?> mapper) {

  return IntegrationFlows
    .from(Kafka
      .messageDrivenChannelAdapter(
        consumerFactory,
        KafkaMessageDrivenChannelAdapter.ListenerMode.record, Topics.CalculationOut)
      .recoveryCallback(
        new ErrorMessageSendingRecoverer(channelCalculatorError(),
        new RawRecordHeaderErrorMessageStrategy())))
    .log(Level.INFO, "kafka -> channel")
    .transform(Transformers.fromJson(CalculationResponse.class, mapper))
    .channel(Channels.CalculationOut)
    .get();
}
----

== Core app

Este proyecto está construído con _grade_ en lugar de _maven_. Básicamente escucha un _topic_ de Kafka y cuando recibe
los mensajes invoca la lógica de negocio y escribe los resultados en otro _topic_.

Esto lo hacemos a través de la siguiente configuración:

[source,java]
----
IntegrationFlow flowFromKafkaDummy(
    KafkaTemplate<String, String> kafkaTemplate,
    ConsumerFactory<String, String> consumerFactory,
    JsonObjectMapper<?, ?> mapper) {

  return IntegrationFlows
    .from(
      Kafka.messageDrivenChannelAdapter(consumerFactory, Topics.CalculationIn))
    .log(Level.INFO, "processing kafka message")
    .transform(Transformers.fromJson(mapper))
    .handle(CalculationRequest.class, (request, headers) -> coreCalculator.calculate(request))
    .transform(Transformers.toJson(mapper))
    .handle(
      Kafka.outboundChannelAdapter(kafkaTemplate)
      .messageKey(MessageKeys.CalculationMessageKey)
      .topic(Topics.CalculationOut))
    .get();
}
----

El proceso de cálculo es muy sencillo. Leerá de mongo una serie de valores preestablecidos en función del valor
del campo _source_ recibido, generará un importe al azar combinándolo con el valor base y devolverá el resultado.

Adicionalmente almacenará en mongo una referencia al cálculo solicitado:

----
> db.calculationHistory.find()
{ "_id" : ObjectId("5b056eb7457e766f43b70d4d"), "request" : { "source" : "test" }, "response" : { "amount" : "72.11", "calculated" : ISODate("2018-05-23T13:37:59.948Z") }, "_class" : "org.lab.tariff.calculator.core.domain.CalculationHistory" }
----

== Infraestructura en local

Para este ejemplo utilizaremos una versión dockerizada de Kafka basada en https://hub.docker.com/r/wurstmeister/kafka/.

En primer lugar adaptaremos nuestro _docker-compose.yml_ (dentro del repositorio está en la carpeta _env_) actualizando
el _KAFKA_ADVERTISED_HOST_NAME_ la IP de nuestro bridge de docker (podemos consultarla ejecutando el comando _docker
network inspect bridge_):

[source,yml]
----
version: '2'
services:

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: "tf-zookeeper"
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    container_name: "tf-kafka"
    ports:
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.17.0.1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "tf-calculator-in:1:3,tf-calculator-out:1:1:compact"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  mongodb:
    image: mongo:latest
    container_name: "tf-mongodb"
    environment:
      - MONGO_DATA_DIR=/data/db
      - MONGO_LOG_DIR=/dev/null
    #volumes:
    #  - ./data/db:/data/db
    ports:
      - 27017:27017
    command: mongod --smallfiles --logpath=/dev/null # --quiet

---- 

Una vez actualizada levantaremos los contenedores a través del comando:

----
docker-compose up -d
----

Una vez estén levantados los contenedores de mongodb, zookeeper y kafka consultaremos la IP de kafka para actualizar nuestra
configuración:

[source,bash]
----
lab@lab:~/repositories/labcabrera/sample-spring-integration-kafka$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
047b473973a4        bridge              bridge              local
2bf80c4e2616        env_default         bridge              local
c52e5dc6a807        host                host                local
89657ae6adc9        none                null                local
lab@lab:~/repositories/labcabrera/sample-spring-integration-kafka$ docker network inspect env_default 
[
    {
        "Name": "env_default",
        "Id": "2bf80c4e2616b0958fc8885eaae34082c5b87119f88aedd257ef5a2b88b1e050",
        "Created": "2018-05-23T12:18:04.801746254+01:00",
        "Scope": "local",
        "Driver": "bridge",
        "EnableIPv6": false,
        "IPAM": {
            "Driver": "default",
            "Options": null,
            "Config": [
                {
                    "Subnet": "172.18.0.0/16",
                    "Gateway": "172.18.0.1"
                }
            ]
        },
        "Internal": false,
        "Attachable": false,
        "Ingress": false,
        "ConfigFrom": {
            "Network": ""
        },
        "ConfigOnly": false,
        "Containers": {
            "28f92d58d984d74d74d380a0e3893d0fe418590fce09ef4f447832f2facd2d83": {
                "Name": "tf-mongodb",
                "EndpointID": "769e86f49265a1fdcaf404aa5c5276c3b708618961207c9f88dc2f921a35d6d3",
                "MacAddress": "02:42:ac:12:00:02",
                "IPv4Address": "172.18.0.2/16",
                "IPv6Address": ""
            },
            "2b30d547f0cffc1d4d4923034f816d03f91cfea00501f3b7e909c4284fda57c6": {
                "Name": "tf-kafka",
                "EndpointID": "963c7aecd8bb5ccff8d5b8fd34372f72fa27aae150e58710fccb8d81200ac283",
                "MacAddress": "02:42:ac:12:00:04",
                "IPv4Address": "172.18.0.4/16",
                "IPv6Address": ""
            },
            "8eb3f74bd3afbc13869de0bccc7e8b07597eaad8a0d168778ee46d395f340317": {
                "Name": "tf-zookeeper",
                "EndpointID": "ce1bb3233e85030cca19657bb210fe700fb325df4b89daf4dfdfe7f8b0edfa93",
                "MacAddress": "02:42:ac:12:00:03",
                "IPv4Address": "172.18.0.3/16",
                "IPv6Address": ""
            }
        },
        "Options": {},
        "Labels": {}
    }
]

----

En este caso el valor 172.18.0.4 será el que estableceremos en nuestro _yml_ de configuración tanto del proyecto core como del gateway.

////
----
# metodo anterior no valido por problemas de incompatibilidad de la version de kafka con la de spring
docker pull spotify/kafka
docker run -d -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=localhost --env ADVERTISED_PORT=9092 --name kafka spotify/kafka
docker exec kafka /opt/kafka_2.11-0.10.1.0/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic tf-calculator-in
docker exec kafka /opt/kafka_2.11-0.10.1.0/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic tf-calculator-out
----
////

== Probado el sistema localmente

En local podemos hacer una petición a la API REST para que envíe el mensaje a Kafka.

----
$ curl -d '{"source":"test"}' -H "Content-Type: application/json" http://localhost:8080/api/v1/calculator
{"reference":"5b056eb7457e766f43b70d4d","amount":72.11,"calculated":"2018-05-23T13:37:59.948+0000"}
----



== Siguientes pasos

* Integración PAAS: service discovery / distributed configuration
* Dockerización de los 2 microservicios (plugins de maven y gradle)
* Gestión de canales de errores
* Registro dinámico de pipelines con Spring DSL

== Referencias

* https://github.com/spring-projects/spring-integration-samples/tree/master/dsl/kafka-dsl
* https://github.com/labcabrera/sample-spring-kafka
* https://github.com/wurstmeister/kafka-docker
* https://github.com/spring-projects/spring-integration-java-dsl/blob/master/src/test/java/org/springframework/integration/dsl/test/kafka/KafkaTests.java
